{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston House Prices\n",
    "\n",
    "The following notebook will attempt to address the following:\n",
    "\n",
    "This assessment concerns the well-known Boston House Prices [1] dataset and the\n",
    "Python [3] packages scipy [2], keras [7], and jupyter [6]. \n",
    "\n",
    "There are three parts which will be addressed:\n",
    "\n",
    "Describe: Create a git repository and make it available online for the lecturer\n",
    "to clone. The repository should contain all your work for this assessment. Within\n",
    "the repository, create a jupyter [6] notebook that uses descriptive statistics and\n",
    "plots to describe the Boston House Prices [1] dataset. This part is worth 20% of\n",
    "your overall mark.\n",
    "Infer: To the above jupyter notebook, add a section where you use inferential\n",
    "statistics to analyse whether there is a significant difference in median house prices\n",
    "between houses that are along the Charles river and those that aren’t. You should\n",
    "explain and discuss your findings within the notebook. This part is also worth\n",
    "20%.\n",
    "Predict: Again using the same notebook, use keras [7] to create a neural network\n",
    "that can predict the median house price based on the other variables in the dataset.\n",
    "You are free to interpret this as you wish — for example, you may use all the other\n",
    "variables, or select a subset. This part is worth 60%.\n",
    "\n",
    "\n",
    "The minimum standard for this assessment is a git repository containing a README file\n",
    "written in Markdown [5] and a jupyter notebook containing your work. The README\n",
    "should contain a summary of your work and provide instructions as to how to run the\n",
    "jupyter notebook and the web application. A better project will be well laid out, clear\n",
    "and concise, and easily understood and run.\n",
    "\n",
    "Note I will rewite the above. I will leave this in the first cell as a guide to myself while completing the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Description of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston House prices dataset is drawn from the Boston Standard Metropolitan Statisical Area in 1970. Each record describes a Boston suburb or town. There are several attributes included for each of these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import housing.csv #importing the dataset\n",
    "boston_dataset = housing()\n",
    "print(boston_dataset.keys()) #this prints the variables within the dataset with the keys and explanations\n",
    "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n",
    "pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.isnull().sum()\n",
    "sns.set(rc = {'figure.figsize':(11.7,8.27)})\n",
    "sns.distplot(boston['MEDV'], bins = 30)\n",
    "plt.show()\n",
    "correlation_matrix = boston.corr().round(2) # creates a correlation matrix between the variables\n",
    "sns.heatmap(data = correlation_matrix, annot = True) #creates a heatmap of the correlation data, a value close to -1 stands for a negative correlation, a value close to 1 means a positive correlation\n",
    "plt.figure(figsize = (20, 5))\n",
    "features = ['STAT', 'RM']\n",
    "target = boston['MEDV']\n",
    "\n",
    "for i, col in enumerate (features):\n",
    "    plt.subplot (l, len(features), i + 1)\n",
    "    x = boston[col]\n",
    "    y = target\n",
    "    plt.scatter(x, y, marker = 'o')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ef19c286457c>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ef19c286457c>\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    rmse =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#training and testing the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)\n",
    "\n",
    "#evaluating the training set\n",
    "y_train_predict = lin_model.predict(X_train)\n",
    "rmse = (up.sqrt(mean_squared.error(Y_train, y_train_predict)))\n",
    "r2 = r2_score(Y_train, y_train_predict)\n",
    "print(\"The performance of the model for the training set is\")\n",
    "print(\"**************************************\")\n",
    "print('The RMSE is {}'.format(rmse))\n",
    "print('The R2 score is{}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "#evaluating the test set\n",
    "y_test_predict = lin_model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "r2 = r2_score(Y_test, _test_predict)\n",
    "print(\"The performance of the model for the testing set is\")\n",
    "print(\"**************************************\")\n",
    "print('The RMSE is {}'.format(rmse))\n",
    "print('The R2 score is {}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inferential statistics for the Charles River House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predict: Creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
