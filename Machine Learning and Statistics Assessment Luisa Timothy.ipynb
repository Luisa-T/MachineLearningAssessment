{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston House Prices\n",
    "\n",
    "The following notebook will attempt to address the following:\n",
    "\n",
    "This assessment concerns the well-known Boston House Prices [1] dataset and the\n",
    "Python [3] packages scipy [2], keras [7], and jupyter [6]. \n",
    "\n",
    "There are three parts which will be addressed:\n",
    "***\n",
    "Describe: Create a git repository and make it available online for the lecturer\n",
    "to clone. The repository should contain all your work for this assessment. Within\n",
    "the repository, create a jupyter [6] notebook that uses descriptive statistics and\n",
    "plots to describe the Boston House Prices [1] dataset. This part is worth 20% of\n",
    "your overall mark.\n",
    "\n",
    "***\n",
    "Infer: To the above jupyter notebook, add a section where you use inferential\n",
    "statistics to analyse whether there is a significant difference in median house prices\n",
    "between houses that are along the Charles river and those that aren’t. You should\n",
    "explain and discuss your findings within the notebook. This part is also worth\n",
    "20%.\n",
    "***\n",
    "Predict: Again using the same notebook, use keras [7] to create a neural network\n",
    "that can predict the median house price based on the other variables in the dataset.\n",
    "You are free to interpret this as you wish — for example, you may use all the other\n",
    "variables, or select a subset. This part is worth 60%.\n",
    "\n",
    "\n",
    "The minimum standard for this assessment is a git repository containing a README file\n",
    "written in Markdown [5] and a jupyter notebook containing your work. The README\n",
    "should contain a summary of your work and provide instructions as to how to run the\n",
    "jupyter notebook and the web application. A better project will be well laid out, clear\n",
    "and concise, and easily understood and run.\n",
    "\n",
    "Note I will rewite the above. I will leave this in the first cell as a guide to myself while completing the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Description of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston House prices dataset is drawn from the Boston Standard Metropolitan Statisical Area in 1970. Each record describes a Boston suburb or town. There are several attributes included for each of these records. There are 506 records and each of these has 13 variables, which may have an influence on the pricing of the houses in question. The aim is to predict the house prices using the 13 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "boston = pd.read_csv('https://www.kaggle.com/vikrishnan/boston-house-prices#housing.csv', sep='delimiter', header=None, engine='python', encoding='utf8')\n",
    "\n",
    "#to print out the variables within the dataset with their keys and explanations\n",
    "\n",
    "print(boston.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.keys())\n",
    "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n",
    "#this will print out the variables and an explanation of them\n",
    "boston.dataset.DESCR \n",
    "pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if any variables have missing values in the dataset\n",
    "boston.isnull().sum()\n",
    "sns.set(rc = {'figure.figsize':(11.7,8.27)})\n",
    "sns.distplot(boston['MEDV'], bins = 30)\n",
    "plt.show()\n",
    "# create a correlation matrix between the variables\n",
    "correlation_matrix = boston.corr().round(2)\n",
    "\n",
    "# create a heatmap of the correlation data, a value close to -1 stands for a negative correlation, a value close to 1 means a positive correlation\n",
    "sns.heatmap(data = correlation_matrix, annot = True)\n",
    "plt.figure(figsize = (20, 5))\n",
    "features = ['STAT', 'RM']\n",
    "target = boston['MEDV']\n",
    "\n",
    "for i, col in enumerate (features):\n",
    "    plt.subplot (l, len(features), i + 1)\n",
    "    x = boston[col]\n",
    "    y = target\n",
    "    plt.scatter(x, y, marker = 'o')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ef19c286457c>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ef19c286457c>\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    rmse =\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training and testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#training and testing the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, Y_train)\n",
    "\n",
    "#evaluating the training set\n",
    "y_train_predict = lin_model.predict(X_train)\n",
    "rmse = (up.sqrt(mean_squared.error(Y_train, y_train_predict)))\n",
    "r2 = r2_score(Y_train, y_train_predict)\n",
    "print(\"The performance of the model for the training set is\")\n",
    "print(\"**************************************\")\n",
    "print('The RMSE is {}'.format(rmse))\n",
    "print('The R2 score is{}'.format(r2))\n",
    "print(\"\\n\")\n",
    "\n",
    "#evaluating the test set\n",
    "y_test_predict = lin_model.predict(X_test)\n",
    "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "r2 = r2_score(Y_test, _test_predict)\n",
    "print(\"The performance of the model for the testing set is\")\n",
    "print(\"**************************************\")\n",
    "print('The RMSE is {}'.format(rmse))\n",
    "print('The R2 score is {}'.format(r2))\n",
    "\n",
    "# TODO: Import 'train_test_split'\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# TODO: Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inferential statistics for the Charles River House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum price of the data\n",
    "minimum_price = np.amin(prices)\n",
    "\n",
    "# Maximum price of the data\n",
    "maximum_price = np.amax(prices)\n",
    "\n",
    "# Mean price of the data\n",
    "mean_price = np.mean(prices)\n",
    "\n",
    "# Median price of the data\n",
    "median_price = np.median(prices)\n",
    "\n",
    "# Standard deviation of prices of the data\n",
    "std_price = np.std(prices)\n",
    "\n",
    "# Show the calculated statistics\n",
    "print(\"Statistics for Boston housing dataset:\\n\")\n",
    "print(\"Minimum price: ${}\".format(minimum_price)) \n",
    "print(\"Maximum price: ${}\".format(maximum_price))\n",
    "print(\"Mean price: ${}\".format(mean_price))\n",
    "print(\"Median price ${}\".format(median_price))\n",
    "print(\"Standard deviation of prices: ${}\".format(std_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predict: Creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "# take a look at the data\n",
    "\n",
    "print(f'Training data : {train_data.shape}')\n",
    "print(f'Test data : {test_data.shape}')\n",
    "print(f'Training sample : {train_data[0]}')\n",
    "print(f'Training target sample : {train_targets[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print(f'Processing fold # {i}')\n",
    "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "                            [train_data[:i * num_val_samples],\n",
    "                            train_data[(i+1) * num_val_samples:]],\n",
    "                            axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "                            [train_targets[:i * num_val_samples],\n",
    "                            train_targets[(i+1)*num_val_samples:]],\n",
    "                            axis=0)\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data,\n",
    "              partial_train_targets,\n",
    "              epochs=num_epochs,\n",
    "              batch_size=1,\n",
    "              verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'all_scores : {all_scores}')\n",
    "print(f'mean all scores : {np.mean(all_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.fit(train_data, train_targets, epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "https://www.ritchieng.com/machine-learning-project-boston-home-prices/\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n",
    "https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155\n",
    "https://towardsdatascience.com/machine-learning-project-predicting-boston-house-prices-with-regression-b4e47493633d\n",
    "https://www.kaggle.com/shanekonaung/boston-housing-price-dataset-with-keras\n",
    "https://www.kaggle.com/callmejeffery/boston-house-price-with-keras\n",
    "https://hackernoon.com/build-your-first-neural-network-to-predict-house-prices-with-keras-3fb0839680f4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
